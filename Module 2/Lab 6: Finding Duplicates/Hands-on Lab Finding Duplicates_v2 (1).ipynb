{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Duplicates Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is a critical step in preparing datasets for analysis, and handling duplicates plays a key role in ensuring data accuracy. In this lab, you will focus on identifying and removing duplicate entries from your dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify duplicate rows in the dataset and analyze their characteristics.\n",
    "2. Visualize the distribution of duplicates based on key attributes.\n",
    "3. Remove duplicate values strategically based on specific criteria.\n",
    "4. Outline the process of verifying and documenting duplicate removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the needed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the dataset into a dataframe**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read Data</h2>\n",
    "<p>\n",
    "We utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "(65457, 114)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset directly from the URL\n",
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VYPrOu0Vs3I0hKLLjiPGrA/survey-data-with-duplicate.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a pandas dataframe:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you are working on a local Jupyter environment, you can use the URL directly in the pandas.read_csv() function as shown below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and Analyze Duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Identify Duplicate Rows\n",
    "1. Count the number of duplicate rows in the dataset.\n",
    "3. Display the first few duplicate rows to understand their structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "       ResponseId                      MainBranch                 Age  \\\n",
      "65437           1  I am a developer by profession  Under 18 years old   \n",
      "65438           2  I am a developer by profession     35-44 years old   \n",
      "65439           3  I am a developer by profession     45-54 years old   \n",
      "65440           4           I am learning to code     18-24 years old   \n",
      "65441           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "                Employment RemoteWork   Check  \\\n",
      "65437  Employed, full-time     Remote  Apples   \n",
      "65438  Employed, full-time     Remote  Apples   \n",
      "65439  Employed, full-time     Remote  Apples   \n",
      "65440   Student, full-time        NaN  Apples   \n",
      "65441   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                        CodingActivities  \\\n",
      "65437                                              Hobby   \n",
      "65438  Hobby;Contribute to open-source projects;Other...   \n",
      "65439  Hobby;Contribute to open-source projects;Other...   \n",
      "65440                                                NaN   \n",
      "65441                                                NaN   \n",
      "\n",
      "                                                 EdLevel  \\\n",
      "65437                          Primary/elementary school   \n",
      "65438       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "65439    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "65440  Some college/university study without earning ...   \n",
      "65441  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                               LearnCode  \\\n",
      "65437                             Books / Physical media   \n",
      "65438  Books / Physical media;Colleague;On the job tr...   \n",
      "65439  Books / Physical media;Colleague;On the job tr...   \n",
      "65440  Other online resources (e.g., videos, blogs, f...   \n",
      "65441  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                         LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "65437                                                NaN  ...            NaN   \n",
      "65438  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "65439  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "65440  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "65441  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "      JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "65437            NaN            NaN            NaN             NaN   \n",
      "65438            0.0            0.0            0.0             0.0   \n",
      "65439            NaN            NaN            NaN             NaN   \n",
      "65440            NaN            NaN            NaN             NaN   \n",
      "65441            NaN            NaN            NaN             NaN   \n",
      "\n",
      "      JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly  \\\n",
      "65437             NaN                    NaN        NaN                 NaN   \n",
      "65438             0.0                    NaN        NaN                 NaN   \n",
      "65439             NaN  Appropriate in length       Easy                 NaN   \n",
      "65440             NaN               Too long       Easy                 NaN   \n",
      "65441             NaN              Too short       Easy                 NaN   \n",
      "\n",
      "      JobSat  \n",
      "65437    NaN  \n",
      "65438    NaN  \n",
      "65439    NaN  \n",
      "65440    NaN  \n",
      "65441    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Count the number of duplicate rows\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(num_duplicates)\n",
    "\n",
    "# Display the first few duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(duplicate_rows.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Analyze Characteristics of Duplicates\n",
    "1. Identify duplicate rows based on selected columns such as MainBranch, Employment, and RemoteWork. Analyse which columns frequently contain identical values within these duplicate rows.\n",
    "2. Analyse the characteristics of rows that are duplicates based on a subset of columns, such as MainBranch, Employment, and RemoteWork. Determine which columns frequently have identical values across these rows.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# Identify columns with the same values in duplicate rows\n",
    "duplicate_columns = df[df.duplicated()].apply(lambda row: row.unique(), axis=0)\n",
    "\n",
    "# Analyze the distribution of duplicates across different columns\n",
    "country_dist = df[df.duplicated()]['Country'].value_counts()\n",
    "employment_dist = df[df.duplicated()]['Employment'].value_counts()\n",
    "devtype_dist = df[df.duplicated()]['DevType'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Columns with same values in duplicate rows:\")\n",
    "print(duplicate_columns)\n",
    "\n",
    "print(\"\\nDistribution of duplicates by Country:\")\n",
    "print(country_dist)\n",
    "\n",
    "print(\"\\nDistribution of duplicates by Employment:\")\n",
    "print(employment_dist)\n",
    "\n",
    "print(\"\\nDistribution of duplicates by DevType:\")\n",
    "print(devtype_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Visualize Duplicates Distribution\n",
    "1. Create visualizations to show the distribution of duplicates across different categories.\n",
    "2. Use bar charts or pie charts to represent the distribution of duplicates by Country and Employment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Visualize distribution of duplicates by Country using a bar chart\n",
    "country_dist = df[df.duplicated()]['Country'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "country_dist.plot(kind='bar')\n",
    "plt.title('Distribution of Duplicates by Country')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Number of Duplicates')\n",
    "plt.show()\n",
    "\n",
    "# Visualize distribution of duplicates by Employment using a pie chart\n",
    "employment_dist = df[df.duplicated()]['Employment'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "employment_dist.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Duplicates by Employment')\n",
    "plt.ylabel('')  # Hide y-label for pie chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Strategic Removal of Duplicates\n",
    "1. Decide which columns are critical for defining uniqueness in the dataset.\n",
    "2. Remove duplicates based on a subset of columns if complete row duplication is not a good criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# Decide on a subset of columns that are critical for defining uniqueness\n",
    "subset_columns = ['ResponseId', 'MainBranch', 'Age', 'Employment', 'Country', 'DevType']\n",
    "\n",
    "# Remove duplicates based on the subset of columns\n",
    "df_unique = df.drop_duplicates(subset=subset_columns)\n",
    "\n",
    "# Verify the number of rows after removing duplicates\n",
    "print(df_unique.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify and Document Duplicate Removal Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Documentation\n",
    "1. Document the process of identifying and removing duplicates.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Documentation: Identifying and Removing Duplicates\n",
    "Step 1: Identify Duplicate Rows\n",
    "First, we counted the number of duplicate rows in the dataset to understand the extent of duplication. We also displayed a few of the duplicate rows to get an insight into their structure.\n",
    "\n",
    "Step 2: Analyze Characteristics of Duplicates\n",
    "Next, we analyzed which columns had the same values in the duplicate rows. Additionally, we examined the distribution of duplicates across different columns like Country, Employment, and DevType.\n",
    "\n",
    "Step 3: Visualize Duplicates Distribution\n",
    "We created visualizations to show the distribution of duplicates across different categories. Bar charts and pie charts were used to represent the distribution of duplicates by country and employment, respectively.\n",
    "\n",
    "Step 4: Strategic Removal of Duplicates\n",
    "Deciding which columns were critical for defining uniqueness in the dataset, we removed duplicates based on a subset of columns. This helped in retaining unique entries in the dataset.\n",
    "\n",
    "Conclusion\n",
    "By strategically identifying and removing duplicates, we cleaned the dataset, ensuring that it only contains unique entries based on key columns. This step is crucial for maintaining the integrity and accuracy of our data analysis.\n",
    "\n",
    "Explain the reasoning behind selecting specific columns for identifying and removing duplicates.\n",
    "When deciding which columns to use for identifying and removing duplicates, it’s essential to select rows that uniquely identify each record or are critical to the analysis. Here are the reasons for choosing each of the specific columns in this context:\n",
    "\n",
    "ResponseId:\n",
    "This is a unique identifier for each respondent. Including this ensures that every survey participant is considered unique, which helps avoid removing genuine, unique responses.\n",
    "\n",
    "MainBranch:\n",
    "This column represents the respondent’s primary role, which is fundamental to understanding their perspective and responses. It’s crucial for identifying duplicates to keep the data integrity intact for analysis on roles.\n",
    "\n",
    "Age:\n",
    "Age is a significant demographic factor. Having it in the subset helps differentiate between respondents who might share other attributes but belong to different age groups, ensuring a more accurate representation of diverse age groups.\n",
    "\n",
    "Employment:\n",
    "Employment status can vary significantly among respondents. This column helps maintain the distinction between different employment situations, which is important for any employment-related analysis.\n",
    "\n",
    "Country:\n",
    "Country of residence is another critical demographic attribute. It ensures that responses from different countries are uniquely identified, reflecting the global diversity of the survey participants.\n",
    "\n",
    "DevType:\n",
    "This column indicates the type of development work the respondent does. It’s important for differentiating between various developer roles and understanding the distribution of skills and roles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explain the reasoning behind selecting specific columns for identifying and removing duplicates.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Overall Reasoning:\n",
    "By selecting these specific columns, the goal was to maintain the uniqueness of each respondent while ensuring that duplicates are identified and removed accurately. These columns collectively cover unique identifiers (ResponseId), demographics (Age, Country), employment details (Employment), and role-specific information (MainBranch, DevType). This approach ensures that the data remains comprehensive and representative after removing duplicates, without losing critical information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Next Steps\n",
    "**In this lab, you focused on identifying and analyzing duplicate rows within the dataset.**\n",
    "\n",
    "- You employed various techniques to explore the nature of duplicates and applied strategic methods for their removal.\n",
    "- For additional analysis, consider investigating the impact of duplicates on specific analyses and how their removal affects the results.\n",
    "- This version of the lab is more focused on duplicate analysis and handling, providing a structured approach to deal with duplicates in a dataset effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11- 05|1.3|Madhusudhan Moole|Updated lab|\n",
    "|2024-10-28|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-24|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-23|1.0|Raghul Ramesh|Created lab|\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "fa3493caccf457f2b33a3a72ca6bf5789c2ce4157ea6e40534b09cc8380e8ae5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
